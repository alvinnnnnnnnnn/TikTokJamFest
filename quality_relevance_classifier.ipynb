{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# ML system for classifying Google location reviews quality and relevance\n",
        "# Labels:\n",
        "# 0: Low Quality\n",
        "# 1: High Quality\n",
        "# 2: Fake\n",
        "# 3: Irrelevant\n",
        "# 4: Advertisement\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Optional deep models\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    CROSSENCODER_AVAILABLE = True\n",
        "except Exception:\n",
        "    CROSSENCODER_AVAILABLE = False\n",
        "\n",
        "DATA_PATH = \"dataset/final_df.csv\"\n",
        "OUTPUT_PATH = \"dataset/predictions.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset and basic preprocessing\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Normalize expected columns\n",
        "TEXT_COL = \"Review Text\"\n",
        "PLACE_WEBSITE_COL = \"website\"\n",
        "BUSINESS_NAME_COL = \"Business Name\"\n",
        "ADDRESS_COL = \"Address\"\n",
        "CATEGORY_COL = \"Category\"\n",
        "LANG_COL = \"lang_code\" if \"lang_code\" in df.columns else None\n",
        "REVIEW_LEN_COL = \"review_length\" if \"review_length\" in df.columns else None\n",
        "EMPTY_COL = \"empty_review\" if \"empty_review\" in df.columns else None\n",
        "EXISTING_TOPIC_REL_COL = \"topic_relevance\" if \"topic_relevance\" in df.columns else None\n",
        "\n",
        "# Fill NaNs for text\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
        "\n",
        "# Convenience: basic lengths if not present\n",
        "if REVIEW_LEN_COL is None:\n",
        "    REVIEW_LEN_COL = \"_auto_review_length\"\n",
        "    df[REVIEW_LEN_COL] = df[TEXT_COL].str.split().apply(len)\n",
        "\n",
        "if EMPTY_COL is None:\n",
        "    EMPTY_COL = \"_auto_empty_review\"\n",
        "    df[EMPTY_COL] = df[TEXT_COL].str.strip().eq(\"\").astype(int)\n",
        "\n",
        "# Quick preview\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rule-based detectors: Low Quality and Advertisement\n",
        "\n",
        "URL_REGEX = re.compile(r\"https?://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
        "SHORT_GENERIC_PATTERNS = [\n",
        "    r\"^good$\", r\"^nice$\", r\"^ok$\", r\"^okay$\", r\"^bad$\", r\"^meh$\",\n",
        "    r\"^great$\", r\"^awesome$\", r\"^terrible$\", r\"^worst$\", r\"^best$\",\n",
        "]\n",
        "SHORT_GENERIC_RE = re.compile(\"|\".join(SHORT_GENERIC_PATTERNS), re.IGNORECASE)\n",
        "\n",
        "AD_KEYWORDS = [\n",
        "    \"promo\", \"promotion\", \"discount\", \"sale\", \"deal\", \"sponsored\", \"visit our website\",\n",
        "    \"click here\", \"buy now\", \"limited time\", \"offer\", \"coupon\", \"voucher\"\n",
        "]\n",
        "AD_RE = re.compile(r\"|\".join([re.escape(k) for k in AD_KEYWORDS]), re.IGNORECASE)\n",
        "\n",
        "\n",
        "def extract_urls(text: str) -> List[str]:\n",
        "    return URL_REGEX.findall(text or \"\")\n",
        "\n",
        "\n",
        "def is_low_quality(text: str, review_len: int, empty_flag: int, min_words: int = 8) -> bool:\n",
        "    if empty_flag == 1:\n",
        "        return True\n",
        "    if review_len < min_words:\n",
        "        # very short or generic\n",
        "        if SHORT_GENERIC_RE.search(text.strip()) is not None:\n",
        "            return True\n",
        "        # short and mostly punctuation/emojis\n",
        "        alnum_ratio = (sum(ch.isalnum() for ch in text) / max(1, len(text)))\n",
        "        if alnum_ratio < 0.2:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def url_domain(url: str) -> Optional[str]:\n",
        "    try:\n",
        "        return urlparse(url).netloc\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_domain(domain: Optional[str]) -> Optional[str]:\n",
        "    if domain is None:\n",
        "        return None\n",
        "    domain = domain.lower()\n",
        "    if domain.startswith(\"www.\"):\n",
        "        domain = domain[4:]\n",
        "    return domain\n",
        "\n",
        "\n",
        "def is_advertisement(text: str, place_website: Optional[str]) -> bool:\n",
        "    urls = extract_urls(text)\n",
        "    if not urls and AD_RE.search(text or \"\") is None:\n",
        "        return False\n",
        "    if urls:\n",
        "        place_domain = normalize_domain(url_domain(place_website)) if place_website else None\n",
        "        for u in urls:\n",
        "            d = normalize_domain(url_domain(u))\n",
        "            if d and place_domain and d.endswith(place_domain):\n",
        "                # URL points to same business domain → not ad\n",
        "                return False\n",
        "        # external links present\n",
        "        return True\n",
        "    # No links but strong ad wording\n",
        "    return AD_RE.search(text or \"\") is not None\n",
        "\n",
        "\n",
        "# Apply rule detectors\n",
        "rule_low_quality = df.apply(lambda r: is_low_quality(r[TEXT_COL], int(r[REVIEW_LEN_COL]), int(r[EMPTY_COL])), axis=1)\n",
        "rule_ad = df.apply(lambda r: is_advertisement(r[TEXT_COL], r.get(PLACE_WEBSITE_COL, None)), axis=1)\n",
        "\n",
        "df[\"rule_low_quality\"] = rule_low_quality.astype(int)\n",
        "df[\"rule_advertisement\"] = rule_ad.astype(int)\n",
        "\n",
        "# Preview counts\n",
        "df[[\"rule_low_quality\", \"rule_advertisement\"]].mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Relevance scoring: CrossEncoder (semantic relevance to location)\n",
        "\n",
        "if CROSSENCODER_AVAILABLE:\n",
        "    model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "    cross_encoder = CrossEncoder(model_name)\n",
        "else:\n",
        "    cross_encoder = None\n",
        "\n",
        "\n",
        "def build_relevance_queries(row: pd.Series) -> List[str]:\n",
        "    fields = []\n",
        "    for col in [BUSINESS_NAME_COL, ADDRESS_COL, CATEGORY_COL]:\n",
        "        if col in row and pd.notnull(row[col]) and str(row[col]).strip():\n",
        "            fields.append(str(row[col]))\n",
        "    if not fields:\n",
        "        return [\"the reviewed location\"]\n",
        "    return [\"; \".join(fields)]\n",
        "\n",
        "\n",
        "def score_relevance_batch(texts: List[str], queries: List[str]) -> np.ndarray:\n",
        "    if cross_encoder is None:\n",
        "        # Fallback: use simple heuristic—character overlap ratio\n",
        "        scores = []\n",
        "        for t, q in zip(texts, queries):\n",
        "            tset = set(t.lower().split())\n",
        "            qset = set(q.lower().split())\n",
        "            inter = len(tset & qset)\n",
        "            denom = max(1, len(tset))\n",
        "            scores.append(inter / denom)\n",
        "        return np.array(scores, dtype=float)\n",
        "    pairs = list(zip(queries, texts))\n",
        "    return np.array(cross_encoder.predict(pairs), dtype=float)\n",
        "\n",
        "\n",
        "# Compute relevance scores in mini-batches\n",
        "BATCH = 256\n",
        "relevance_scores = []\n",
        "for i in range(0, len(df), BATCH):\n",
        "    chunk = df.iloc[i:i+BATCH]\n",
        "    texts = chunk[TEXT_COL].tolist()\n",
        "    queries = [build_relevance_queries(r)[0] for _, r in chunk.iterrows()]\n",
        "    relevance_scores.extend(score_relevance_batch(texts, queries))\n",
        "\n",
        "df[\"semantic_relevance\"] = np.array(relevance_scores)\n",
        "df[[\"semantic_relevance\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fake detection heuristic\n",
        "# Signals (weak but helpful): mentions of not visiting, generic praise without specifics, contradictions\n",
        "\n",
        "FAKE_PATTERNS = [\n",
        "    r\"didn't visit\", r\"did not visit\", r\"haven't been\", r\"never been\", r\"not been there\",\n",
        "    r\"paid review\", r\"sponsored review\", r\"fake review\", r\"bot review\", r\"looks nice*\", r\"seems good\",\n",
        "]\n",
        "FAKE_RE = re.compile(\"|\".join(FAKE_PATTERNS), re.IGNORECASE)\n",
        "\n",
        "GENERIC_PRAISE = re.compile(r\"(great|nice|good|amazing|awesome) (place|spot|location|shop|store)\\b\", re.IGNORECASE)\n",
        "\n",
        "\n",
        "def fake_score(text: str) -> float:\n",
        "    if not text or not text.strip():\n",
        "        return 0.0\n",
        "    s = 0.0\n",
        "    if FAKE_RE.search(text):\n",
        "        s += 0.7\n",
        "    if GENERIC_PRAISE.search(text):\n",
        "        s += 0.2\n",
        "    # too many exclamations can be suspicious\n",
        "    if text.count(\"!\") >= 3:\n",
        "        s += 0.1\n",
        "    return min(1.0, s)\n",
        "\n",
        "\n",
        "df[\"fake_score\"] = df[TEXT_COL].apply(fake_score)\n",
        "df[[\"fake_score\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final combiner: produce labels 0-4\n",
        "# Priority: Advertisement (4) > Irrelevant (3) > Fake (2) > Low Quality (0) > High Quality (1)\n",
        "\n",
        "# Thresholds\n",
        "SEMANTIC_REL_THR = 0.25 if not CROSSENCODER_AVAILABLE else 0.35\n",
        "FAKE_THR = 0.6\n",
        "\n",
        "\n",
        "def assign_label(row: pd.Series) -> int:\n",
        "    # 4. Advertisement\n",
        "    if int(row.get(\"rule_advertisement\", 0)) == 1:\n",
        "        return 4\n",
        "    # 3. Irrelevant (low semantic relevance)\n",
        "    if float(row.get(\"semantic_relevance\", 0.0)) < SEMANTIC_REL_THR:\n",
        "        return 3\n",
        "    # 2. Fake (heuristic)\n",
        "    if float(row.get(\"fake_score\", 0.0)) >= FAKE_THR:\n",
        "        return 2\n",
        "    # 0. Low quality (rule)\n",
        "    if int(row.get(\"rule_low_quality\", 0)) == 1:\n",
        "        return 0\n",
        "    # 1. High quality otherwise\n",
        "    return 1\n",
        "\n",
        "\n",
        "df[\"pred_label\"] = df.apply(assign_label, axis=1)\n",
        "\n",
        "# Attach label names for readability\n",
        "ID2LABEL = {0: \"Low Quality\", 1: \"High Quality\", 2: \"Fake\", 3: \"Irrelevant\", 4: \"Advertisement\"}\n",
        "df[\"pred_label_name\"] = df[\"pred_label\"].map(ID2LABEL)\n",
        "\n",
        "df[[\"pred_label\", \"pred_label_name\"]].value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'BUSINESS_NAME_COL' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m output_cols = [\u001b[43mBUSINESS_NAME_COL\u001b[49m, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n\u001b[32m      4\u001b[39m                \u001b[33m\"\u001b[39m\u001b[33mrule_low_quality\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrule_advertisement\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfake_score\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msemantic_relevance\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m                \u001b[33m\"\u001b[39m\u001b[33mpred_label\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpred_label_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output_cols):\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n",
            "\u001b[31mNameError\u001b[39m: name 'BUSINESS_NAME_COL' is not defined"
          ]
        }
      ],
      "source": [
        "# Save predictions\n",
        "\n",
        "output_cols = [BUSINESS_NAME_COL, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n",
        "               \"rule_low_quality\", \"rule_advertisement\", \"fake_score\", \"semantic_relevance\",\n",
        "               \"pred_label\", \"pred_label_name\"]\n",
        "\n",
        "for c in list(output_cols):\n",
        "    if c not in df.columns:\n",
        "        output_cols.remove(c)\n",
        "\n",
        "pred_df = df[output_cols].copy()\n",
        "pred_df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "OUTPUT_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Robustness fixes: safe URL/text handling and improved ad detection\n",
        "\n",
        "def safe_text(x) -> str:\n",
        "    return x if isinstance(x, str) else \"\"\n",
        "\n",
        "\n",
        "def is_nonempty_str(x) -> bool:\n",
        "    return isinstance(x, str) and x.strip() != \"\"\n",
        "\n",
        "\n",
        "def url_domain(url: Optional[str]) -> Optional[str]:\n",
        "    if not is_nonempty_str(url):\n",
        "        return None\n",
        "    try:\n",
        "        return urlparse(url).netloc\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_domain(domain: Optional[str]) -> Optional[str]:\n",
        "    if not is_nonempty_str(domain):\n",
        "        return None\n",
        "    d = domain.lower()\n",
        "    if d.startswith(\"www.\"):\n",
        "        d = d[4:]\n",
        "    return d\n",
        "\n",
        "\n",
        "def extract_urls(text: str) -> List[str]:\n",
        "    return URL_REGEX.findall(safe_text(text))\n",
        "\n",
        "\n",
        "def is_advertisement(text: str, place_website: Optional[str]) -> bool:\n",
        "    urls = extract_urls(text)\n",
        "    has_ad_words = AD_RE.search(safe_text(text)) is not None\n",
        "\n",
        "    if urls:\n",
        "        place_domain = normalize_domain(url_domain(place_website))\n",
        "        link_domains = [normalize_domain(url_domain(u)) for u in urls]\n",
        "        # External if any link domain does not end with the place domain\n",
        "        external_found = False\n",
        "        for d in link_domains:\n",
        "            if d is None:\n",
        "                continue\n",
        "            if place_domain is None or not d.endswith(place_domain):\n",
        "                external_found = True\n",
        "                break\n",
        "        if external_found:\n",
        "            return True\n",
        "        # Only in-domain links → not an ad by rule\n",
        "        return False\n",
        "\n",
        "    # No links: treat strong promotional wording as ad\n",
        "    return has_ad_words\n",
        "\n",
        "\n",
        "# Recompute with robust ad detection and keep low_quality as before\n",
        "df[\"rule_advertisement\"] = df.apply(lambda r: is_advertisement(r[TEXT_COL], r.get(PLACE_WEBSITE_COL, None)), axis=1).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recompute predictions with updated rules\n",
        "\n",
        "df[\"pred_label\"] = df.apply(assign_label, axis=1)\n",
        "df[\"pred_label_name\"] = df[\"pred_label\"].map(ID2LABEL)\n",
        "\n",
        "pred_df = df[[c for c in [BUSINESS_NAME_COL, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n",
        "               \"rule_low_quality\", \"rule_advertisement\", \"fake_score\", \"semantic_relevance\",\n",
        "               \"pred_label\", \"pred_label_name\"] if c in df.columns]].copy()\n",
        "\n",
        "pred_df.to_csv(OUTPUT_PATH, index=False)\n",
        "OUTPUT_PATH\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
