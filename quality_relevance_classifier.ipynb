{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ML system for classifying Google location reviews quality and relevance\n",
        "# Labels:\n",
        "# 0: Low Quality\n",
        "# 1: High Quality\n",
        "# 2: Fake\n",
        "# 3: Irrelevant\n",
        "# 4: Advertisement\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Optional deep models\n",
        "try:\n",
        "    from sentence_transformers import CrossEncoder\n",
        "    CROSSENCODER_AVAILABLE = True\n",
        "except Exception:\n",
        "    CROSSENCODER_AVAILABLE = False\n",
        "\n",
        "DATA_PATH = \"dataset/final_df.csv\"\n",
        "OUTPUT_PATH = \"dataset/predictions.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Business Name</th>\n",
              "      <th>Review</th>\n",
              "      <th>Reviewer Name</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>place_id</th>\n",
              "      <th>Business Rating</th>\n",
              "      <th>Total Reviews</th>\n",
              "      <th>Address</th>\n",
              "      <th>website</th>\n",
              "      <th>phone</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Category</th>\n",
              "      <th>empty_review</th>\n",
              "      <th>lang_code</th>\n",
              "      <th>Review Text Translated</th>\n",
              "      <th>is_translated</th>\n",
              "      <th>mapped_category</th>\n",
              "      <th>review_length</th>\n",
              "      <th>topic_relevance</th>\n",
              "      <th>review_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Anytime Fitness</td>\n",
              "      <td>4</td>\n",
              "      <td>Than pohwai</td>\n",
              "      <td></td>\n",
              "      <td>ChIJ08t6PjYP2jERi4sIp8Z1Sw0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>215</td>\n",
              "      <td>638 Jurong West Street 61, #03-01 Pioneer Mall</td>\n",
              "      <td>https://www.anytimefitness.sg/gyms/sg-0095/pio...</td>\n",
              "      <td>+65 8500 4500</td>\n",
              "      <td>SG</td>\n",
              "      <td>Gym</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>Gym</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Anytime Fitness</td>\n",
              "      <td>1</td>\n",
              "      <td>Rah</td>\n",
              "      <td>Management in this region is not the best! Not...</td>\n",
              "      <td>ChIJ08t6PjYP2jERi4sIp8Z1Sw0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>215</td>\n",
              "      <td>638 Jurong West Street 61, #03-01 Pioneer Mall</td>\n",
              "      <td>https://www.anytimefitness.sg/gyms/sg-0095/pio...</td>\n",
              "      <td>+65 8500 4500</td>\n",
              "      <td>SG</td>\n",
              "      <td>Gym</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "      <td>Management in this region is not the best! Not...</td>\n",
              "      <td>0</td>\n",
              "      <td>Gym</td>\n",
              "      <td>86</td>\n",
              "      <td>0.442945</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anytime Fitness</td>\n",
              "      <td>5</td>\n",
              "      <td>Lin HaiHong</td>\n",
              "      <td>感谢 Desmond 在关键时刻救了一位晕倒的女士，本人真心谢谢见义勇为的你.你是一位好员工...</td>\n",
              "      <td>ChIJ08t6PjYP2jERi4sIp8Z1Sw0</td>\n",
              "      <td>4.7</td>\n",
              "      <td>215</td>\n",
              "      <td>638 Jurong West Street 61, #03-01 Pioneer Mall</td>\n",
              "      <td>https://www.anytimefitness.sg/gyms/sg-0095/pio...</td>\n",
              "      <td>+65 8500 4500</td>\n",
              "      <td>SG</td>\n",
              "      <td>Gym</td>\n",
              "      <td>0</td>\n",
              "      <td>zh-CN</td>\n",
              "      <td>Thank you Desmond for saving a woman who faint...</td>\n",
              "      <td>1</td>\n",
              "      <td>Gym</td>\n",
              "      <td>40</td>\n",
              "      <td>0.127851</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Business Name  Review Reviewer Name  \\\n",
              "0  Anytime Fitness       4   Than pohwai   \n",
              "1  Anytime Fitness       1           Rah   \n",
              "2  Anytime Fitness       5   Lin HaiHong   \n",
              "\n",
              "                                         Review Text  \\\n",
              "0                                                      \n",
              "1  Management in this region is not the best! Not...   \n",
              "2  感谢 Desmond 在关键时刻救了一位晕倒的女士，本人真心谢谢见义勇为的你.你是一位好员工...   \n",
              "\n",
              "                      place_id  Business Rating  Total Reviews  \\\n",
              "0  ChIJ08t6PjYP2jERi4sIp8Z1Sw0              4.7            215   \n",
              "1  ChIJ08t6PjYP2jERi4sIp8Z1Sw0              4.7            215   \n",
              "2  ChIJ08t6PjYP2jERi4sIp8Z1Sw0              4.7            215   \n",
              "\n",
              "                                          Address  \\\n",
              "0  638 Jurong West Street 61, #03-01 Pioneer Mall   \n",
              "1  638 Jurong West Street 61, #03-01 Pioneer Mall   \n",
              "2  638 Jurong West Street 61, #03-01 Pioneer Mall   \n",
              "\n",
              "                                             website          phone  \\\n",
              "0  https://www.anytimefitness.sg/gyms/sg-0095/pio...  +65 8500 4500   \n",
              "1  https://www.anytimefitness.sg/gyms/sg-0095/pio...  +65 8500 4500   \n",
              "2  https://www.anytimefitness.sg/gyms/sg-0095/pio...  +65 8500 4500   \n",
              "\n",
              "  Country Code Category  empty_review lang_code  \\\n",
              "0           SG      Gym             1       NaN   \n",
              "1           SG      Gym             0        en   \n",
              "2           SG      Gym             0     zh-CN   \n",
              "\n",
              "                              Review Text Translated  is_translated  \\\n",
              "0                                                NaN              0   \n",
              "1  Management in this region is not the best! Not...              0   \n",
              "2  Thank you Desmond for saving a woman who faint...              1   \n",
              "\n",
              "  mapped_category  review_length  topic_relevance  review_label  \n",
              "0             Gym              0         0.000000             0  \n",
              "1             Gym             86         0.442945             1  \n",
              "2             Gym             40         0.127851             1  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset and basic preprocessing\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Normalize expected columns\n",
        "TEXT_COL = \"Review Text\"\n",
        "PLACE_WEBSITE_COL = \"website\"\n",
        "BUSINESS_NAME_COL = \"Business Name\"\n",
        "ADDRESS_COL = \"Address\"\n",
        "CATEGORY_COL = \"Category\"\n",
        "LANG_COL = \"lang_code\" if \"lang_code\" in df.columns else None\n",
        "REVIEW_LEN_COL = \"review_length\" if \"review_length\" in df.columns else None\n",
        "EMPTY_COL = \"empty_review\" if \"empty_review\" in df.columns else None\n",
        "EXISTING_TOPIC_REL_COL = \"topic_relevance\" if \"topic_relevance\" in df.columns else None\n",
        "\n",
        "# Fill NaNs for text\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
        "\n",
        "# Convenience: basic lengths if not present\n",
        "if REVIEW_LEN_COL is None:\n",
        "    REVIEW_LEN_COL = \"_auto_review_length\"\n",
        "    df[REVIEW_LEN_COL] = df[TEXT_COL].str.split().apply(len)\n",
        "\n",
        "if EMPTY_COL is None:\n",
        "    EMPTY_COL = \"_auto_empty_review\"\n",
        "    df[EMPTY_COL] = df[TEXT_COL].str.strip().eq(\"\").astype(int)\n",
        "\n",
        "# Quick preview\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rule_low_quality      0.327009\n",
              "rule_advertisement    0.037681\n",
              "dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Rule-based detectors: Low Quality and Advertisement\n",
        "\n",
        "URL_REGEX = re.compile(r\"https?://\\S+|www\\.\\S+\", re.IGNORECASE)\n",
        "SHORT_GENERIC_PATTERNS = [\n",
        "    r\"^good$\", r\"^nice$\", r\"^ok$\", r\"^okay$\", r\"^bad$\", r\"^meh$\",\n",
        "    r\"^great$\", r\"^awesome$\", r\"^terrible$\", r\"^worst$\", r\"^best$\",\n",
        "]\n",
        "SHORT_GENERIC_RE = re.compile(\"|\".join(SHORT_GENERIC_PATTERNS), re.IGNORECASE)\n",
        "\n",
        "AD_KEYWORDS = [\n",
        "    \"promo\", \"promotion\", \"discount\", \"sale\", \"deal\", \"sponsored\", \"visit our website\",\n",
        "    \"click here\", \"buy now\", \"limited time\", \"offer\", \"coupon\", \"voucher\"\n",
        "]\n",
        "AD_RE = re.compile(r\"|\".join([re.escape(k) for k in AD_KEYWORDS]), re.IGNORECASE)\n",
        "\n",
        "\n",
        "def extract_urls(text: str) -> List[str]:\n",
        "    return URL_REGEX.findall(text or \"\")\n",
        "\n",
        "\n",
        "def is_low_quality(text: str, review_len: int, empty_flag: int, min_words: int = 8) -> bool:\n",
        "    if empty_flag == 1:\n",
        "        return True\n",
        "    if review_len < min_words:\n",
        "        # very short or generic\n",
        "        if SHORT_GENERIC_RE.search(text.strip()) is not None:\n",
        "            return True\n",
        "        # short and mostly punctuation/emojis\n",
        "        alnum_ratio = (sum(ch.isalnum() for ch in text) / max(1, len(text)))\n",
        "        if alnum_ratio < 0.2:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def url_domain(url: str) -> Optional[str]:\n",
        "    try:\n",
        "        return urlparse(url).netloc\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_domain(domain: Optional[str]) -> Optional[str]:\n",
        "    if domain is None:\n",
        "        return None\n",
        "    domain = domain.lower()\n",
        "    if domain.startswith(\"www.\"):\n",
        "        domain = domain[4:]\n",
        "    return domain\n",
        "\n",
        "\n",
        "def is_advertisement(text: str, place_website: Optional[str]) -> bool:\n",
        "    urls = extract_urls(text)\n",
        "    if not urls and AD_RE.search(text or \"\") is None:\n",
        "        return False\n",
        "    if urls:\n",
        "        place_domain = normalize_domain(url_domain(place_website)) if place_website else None\n",
        "        for u in urls:\n",
        "            d = normalize_domain(url_domain(u))\n",
        "            if d and place_domain and d.endswith(place_domain):\n",
        "                # URL points to same business domain → not ad\n",
        "                return False\n",
        "        # external links present\n",
        "        return True\n",
        "    # No links but strong ad wording\n",
        "    return AD_RE.search(text or \"\") is not None\n",
        "\n",
        "\n",
        "# Apply rule detectors\n",
        "rule_low_quality = df.apply(lambda r: is_low_quality(r[TEXT_COL], int(r[REVIEW_LEN_COL]), int(r[EMPTY_COL])), axis=1)\n",
        "rule_ad = df.apply(lambda r: is_advertisement(r[TEXT_COL], r.get(PLACE_WEBSITE_COL, None)), axis=1)\n",
        "\n",
        "df[\"rule_low_quality\"] = rule_low_quality.astype(int)\n",
        "df[\"rule_advertisement\"] = rule_ad.astype(int)\n",
        "\n",
        "# Preview counts\n",
        "df[[\"rule_low_quality\", \"rule_advertisement\"]].mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semantic_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3795.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.012835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.040821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       semantic_relevance\n",
              "count         3795.000000\n",
              "mean             0.012835\n",
              "std              0.040821\n",
              "min              0.000000\n",
              "25%              0.000000\n",
              "50%              0.000000\n",
              "75%              0.000000\n",
              "max              0.500000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Relevance scoring: CrossEncoder (semantic relevance to location)\n",
        "\n",
        "if CROSSENCODER_AVAILABLE:\n",
        "    model_name = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "    cross_encoder = CrossEncoder(model_name)\n",
        "else:\n",
        "    cross_encoder = None\n",
        "\n",
        "\n",
        "def build_relevance_queries(row: pd.Series) -> List[str]:\n",
        "    fields = []\n",
        "    for col in [BUSINESS_NAME_COL, ADDRESS_COL, CATEGORY_COL]:\n",
        "        if col in row and pd.notnull(row[col]) and str(row[col]).strip():\n",
        "            fields.append(str(row[col]))\n",
        "    if not fields:\n",
        "        return [\"the reviewed location\"]\n",
        "    return [\"; \".join(fields)]\n",
        "\n",
        "\n",
        "def score_relevance_batch(texts: List[str], queries: List[str]) -> np.ndarray:\n",
        "    if cross_encoder is None:\n",
        "        # Fallback: use simple heuristic—character overlap ratio\n",
        "        scores = []\n",
        "        for t, q in zip(texts, queries):\n",
        "            tset = set(t.lower().split())\n",
        "            qset = set(q.lower().split())\n",
        "            inter = len(tset & qset)\n",
        "            denom = max(1, len(tset))\n",
        "            scores.append(inter / denom)\n",
        "        return np.array(scores, dtype=float)\n",
        "    pairs = list(zip(queries, texts))\n",
        "    return np.array(cross_encoder.predict(pairs), dtype=float)\n",
        "\n",
        "\n",
        "# Compute relevance scores in mini-batches\n",
        "BATCH = 256\n",
        "relevance_scores = []\n",
        "for i in range(0, len(df), BATCH):\n",
        "    chunk = df.iloc[i:i+BATCH]\n",
        "    texts = chunk[TEXT_COL].tolist()\n",
        "    queries = [build_relevance_queries(r)[0] for _, r in chunk.iterrows()]\n",
        "    relevance_scores.extend(score_relevance_batch(texts, queries))\n",
        "\n",
        "df[\"semantic_relevance\"] = np.array(relevance_scores)\n",
        "df[[\"semantic_relevance\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fake_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3795.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.007615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.036047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        fake_score\n",
              "count  3795.000000\n",
              "mean      0.007615\n",
              "std       0.036047\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.000000\n",
              "max       0.700000"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fake detection heuristic\n",
        "# Signals (weak but helpful): mentions of not visiting, generic praise without specifics, contradictions\n",
        "\n",
        "FAKE_PATTERNS = [\n",
        "    r\"didn't visit\", r\"did not visit\", r\"haven't been\", r\"never been\", r\"not been there\",\n",
        "    r\"paid review\", r\"sponsored review\", r\"fake review\", r\"bot review\", r\"looks nice*\", r\"seems good\",\n",
        "]\n",
        "FAKE_RE = re.compile(\"|\".join(FAKE_PATTERNS), re.IGNORECASE)\n",
        "\n",
        "GENERIC_PRAISE = re.compile(r\"(great|nice|good|amazing|awesome) (place|spot|location|shop|store)\\b\", re.IGNORECASE)\n",
        "\n",
        "\n",
        "def fake_score(text: str) -> float:\n",
        "    if not text or not text.strip():\n",
        "        return 0.0\n",
        "    s = 0.0\n",
        "    if FAKE_RE.search(text):\n",
        "        s += 0.7\n",
        "    if GENERIC_PRAISE.search(text):\n",
        "        s += 0.2\n",
        "    # too many exclamations can be suspicious\n",
        "    if text.count(\"!\") >= 3:\n",
        "        s += 0.1\n",
        "    return min(1.0, s)\n",
        "\n",
        "\n",
        "df[\"fake_score\"] = df[TEXT_COL].apply(fake_score)\n",
        "df[[\"fake_score\"]].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pred_label  pred_label_name\n",
              "3           Irrelevant         0.955731\n",
              "4           Advertisement      0.037681\n",
              "1           High Quality       0.006588\n",
              "dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Final combiner: produce labels 0-4\n",
        "# Priority: Advertisement (4) > Irrelevant (3) > Fake (2) > Low Quality (0) > High Quality (1)\n",
        "\n",
        "# Thresholds\n",
        "SEMANTIC_REL_THR = 0.25 if not CROSSENCODER_AVAILABLE else 0.35\n",
        "FAKE_THR = 0.6\n",
        "\n",
        "\n",
        "def assign_label(row: pd.Series) -> int:\n",
        "    # 4. Advertisement\n",
        "    if int(row.get(\"rule_advertisement\", 0)) == 1:\n",
        "        return 4\n",
        "    # 3. Irrelevant (low semantic relevance)\n",
        "    if float(row.get(\"semantic_relevance\", 0.0)) < SEMANTIC_REL_THR:\n",
        "        return 3\n",
        "    # 2. Fake (heuristic)\n",
        "    if float(row.get(\"fake_score\", 0.0)) >= FAKE_THR:\n",
        "        return 2\n",
        "    # 0. Low quality (rule)\n",
        "    if int(row.get(\"rule_low_quality\", 0)) == 1:\n",
        "        return 0\n",
        "    # 1. High quality otherwise\n",
        "    return 1\n",
        "\n",
        "\n",
        "df[\"pred_label\"] = df.apply(assign_label, axis=1)\n",
        "\n",
        "# Attach label names for readability\n",
        "ID2LABEL = {0: \"Low Quality\", 1: \"High Quality\", 2: \"Fake\", 3: \"Irrelevant\", 4: \"Advertisement\"}\n",
        "df[\"pred_label_name\"] = df[\"pred_label\"].map(ID2LABEL)\n",
        "\n",
        "df[[\"pred_label\", \"pred_label_name\"]].value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dataset/predictions.csv'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save predictions\n",
        "\n",
        "output_cols = [BUSINESS_NAME_COL, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n",
        "               \"rule_low_quality\", \"rule_advertisement\", \"fake_score\", \"semantic_relevance\",\n",
        "               \"pred_label\", \"pred_label_name\"]\n",
        "\n",
        "for c in list(output_cols):\n",
        "    if c not in df.columns:\n",
        "        output_cols.remove(c)\n",
        "\n",
        "pred_df = df[output_cols].copy()\n",
        "pred_df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "OUTPUT_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Robustness fixes: safe URL/text handling and improved ad detection\n",
        "\n",
        "def safe_text(x) -> str:\n",
        "    return x if isinstance(x, str) else \"\"\n",
        "\n",
        "\n",
        "def is_nonempty_str(x) -> bool:\n",
        "    return isinstance(x, str) and x.strip() != \"\"\n",
        "\n",
        "\n",
        "def url_domain(url: Optional[str]) -> Optional[str]:\n",
        "    if not is_nonempty_str(url):\n",
        "        return None\n",
        "    try:\n",
        "        return urlparse(url).netloc\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def normalize_domain(domain: Optional[str]) -> Optional[str]:\n",
        "    if not is_nonempty_str(domain):\n",
        "        return None\n",
        "    d = domain.lower()\n",
        "    if d.startswith(\"www.\"):\n",
        "        d = d[4:]\n",
        "    return d\n",
        "\n",
        "\n",
        "def extract_urls(text: str) -> List[str]:\n",
        "    return URL_REGEX.findall(safe_text(text))\n",
        "\n",
        "\n",
        "def is_advertisement(text: str, place_website: Optional[str]) -> bool:\n",
        "    urls = extract_urls(text)\n",
        "    has_ad_words = AD_RE.search(safe_text(text)) is not None\n",
        "\n",
        "    if urls:\n",
        "        place_domain = normalize_domain(url_domain(place_website))\n",
        "        link_domains = [normalize_domain(url_domain(u)) for u in urls]\n",
        "        # External if any link domain does not end with the place domain\n",
        "        external_found = False\n",
        "        for d in link_domains:\n",
        "            if d is None:\n",
        "                continue\n",
        "            if place_domain is None or not d.endswith(place_domain):\n",
        "                external_found = True\n",
        "                break\n",
        "        if external_found:\n",
        "            return True\n",
        "        # Only in-domain links → not an ad by rule\n",
        "        return False\n",
        "\n",
        "    # No links: treat strong promotional wording as ad\n",
        "    return has_ad_words\n",
        "\n",
        "\n",
        "# Recompute with robust ad detection and keep low_quality as before\n",
        "df[\"rule_advertisement\"] = df.apply(lambda r: is_advertisement(r[TEXT_COL], r.get(PLACE_WEBSITE_COL, None)), axis=1).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dataset/predictions.csv'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Recompute predictions with updated rules\n",
        "\n",
        "df[\"pred_label\"] = df.apply(assign_label, axis=1)\n",
        "df[\"pred_label_name\"] = df[\"pred_label\"].map(ID2LABEL)\n",
        "\n",
        "pred_df = df[[c for c in [BUSINESS_NAME_COL, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n",
        "               \"rule_low_quality\", \"rule_advertisement\", \"fake_score\", \"semantic_relevance\",\n",
        "               \"pred_label\", \"pred_label_name\"] if c in df.columns]].copy()\n",
        "\n",
        "pred_df.to_csv(OUTPUT_PATH, index=False)\n",
        "OUTPUT_PATH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3036, 6537), (759, 6537))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Supervised training setup using final_df's review_label\n",
        "\n",
        "LABEL_COL = \"review_label\" if \"review_label\" in df.columns else None\n",
        "assert LABEL_COL is not None, \"The dataset must contain 'review_label' (0-4).\"\n",
        "\n",
        "# Filter rows with non-null labels\n",
        "train_df = df[df[LABEL_COL].notnull()].copy()\n",
        "train_df[LABEL_COL] = train_df[LABEL_COL].astype(int)\n",
        "\n",
        "# Feature: use review text only for now; rules can be added as features later\n",
        "X_text = train_df[TEXT_COL].fillna(\"\").astype(str).tolist()\n",
        "y = train_df[LABEL_COL].values\n",
        "\n",
        "# Split\n",
        "X_train_text, X_val_text, y_train, y_val = train_test_split(\n",
        "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Vectorizer\n",
        "tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1,2),\n",
        "    min_df=3,\n",
        "    max_df=0.95,\n",
        "    strip_accents='unicode',\n",
        "    lowercase=True,\n",
        ")\n",
        "X_train = tfidf.fit_transform(X_train_text)\n",
        "X_val = tfidf.transform(X_val_text)\n",
        "\n",
        "X_train.shape, X_val.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.877     0.929     0.902       322\n",
            "           1      0.919     0.883     0.901       412\n",
            "           2      0.000     0.000     0.000         7\n",
            "           3      0.167     0.167     0.167        18\n",
            "\n",
            "    accuracy                          0.877       759\n",
            "   macro avg      0.491     0.495     0.492       759\n",
            "weighted avg      0.875     0.877     0.876       759\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train TF-IDF + Logistic Regression classifier\n",
        "\n",
        "# Class weights to counter imbalance\n",
        "classes, counts = np.unique(y_train, return_counts=True)\n",
        "class_weight = {int(c): float(len(y_train) / (len(classes) * n)) for c, n in zip(classes, counts)}\n",
        "\n",
        "logreg = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    n_jobs=-1,\n",
        "    class_weight=class_weight,\n",
        "    multi_class='auto',\n",
        ")\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_val_pred = logreg.predict(X_val)\n",
        "print(classification_report(y_val, y_val_pred, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dataset/predictions.csv'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine model prediction with rule overrides (ads) and export\n",
        "\n",
        "# Fit on all labeled text for final model\n",
        "full_X = tfidf.fit_transform(df[TEXT_COL].fillna(\"\").astype(str))\n",
        "full_y = df[LABEL_COL].fillna(-1).astype(int)  # -1 for unlabeled\n",
        "\n",
        "# Retrain on labeled rows only\n",
        "mask_labeled = full_y >= 0\n",
        "final_clf = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced',\n",
        ")\n",
        "final_clf.fit(full_X[mask_labeled], full_y[mask_labeled])\n",
        "\n",
        "# Predict all rows\n",
        "proba_all = final_clf.predict_proba(full_X)\n",
        "pred_all = proba_all.argmax(axis=1)\n",
        "\n",
        "# Ad override takes precedence\n",
        "pred_all = np.where(df[\"rule_advertisement\"].values == 1, 4, pred_all)\n",
        "\n",
        "# Keep low-quality override for empty/very short reviews\n",
        "pred_all = np.where(df[\"rule_low_quality\"].values == 1, 0, pred_all)\n",
        "\n",
        "# Save\n",
        "ID2LABEL = {0: \"Low Quality\", 1: \"High Quality\", 2: \"Fake\", 3: \"Irrelevant\", 4: \"Advertisement\"}\n",
        "df[\"ml_pred_label\"] = pred_all\n",
        "df[\"ml_pred_label_name\"] = df[\"ml_pred_label\"].map(ID2LABEL)\n",
        "\n",
        "out_cols = [BUSINESS_NAME_COL, TEXT_COL, PLACE_WEBSITE_COL, ADDRESS_COL, CATEGORY_COL,\n",
        "            \"ml_pred_label\", \"ml_pred_label_name\",\n",
        "            \"rule_low_quality\", \"rule_advertisement\"]\n",
        "\n",
        "predictions_ml = df[[c for c in out_cols if c in df.columns]].copy()\n",
        "predictions_ml.to_csv(\"dataset/predictions.csv\", index=False)\n",
        "\"dataset/predictions.csv\"\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "CS2109S",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
